{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Graph Neural Network (GNN) Training for Medical Predictions**\n",
    "\n",
    "## **Introduction**\n",
    "This notebook details the end-to-end process of training a **Graph Neural Network (GNN)** for predicting medical conditions. The model learns **patient relationships and medical histories** by leveraging graph-based learning.  \n",
    "\n",
    "We use **PyTorch Geometric (PyG)** for graph construction and **TF-IDF** for patient condition embeddings. The dataset consists of **FHIR-based structured patient records**, which we preprocess before training the model.\n",
    "\n",
    "---\n",
    "\n",
    "## **List of Contents**\n",
    "This notebook is structured into **8 key sections**, covering data extraction, preprocessing, model training, and deployment.\n",
    "\n",
    "### [**1. Extracting FHIR JSON Data (FHIR Extraction)**](#1-extracting-fhir-json-data-fhir-extraction)\n",
    "   **Keywords**: `load_json`, `extract_patients`, `extract_family_member_history`, `extract_related_person`, `extract_conditions`\n",
    "   - Extract **patient details, family medical history, relationships, and conditions** from FHIR JSON files.\n",
    "   - Convert the raw JSON data into **structured Pandas DataFrames** for further processing.\n",
    "\n",
    "### [**2. Preprocessing and Training DataFrame Creation**](#2-preprocessing-and-training-dataframe-creation)\n",
    "   **Keywords**: `df_training`, `df_patient`, `df_fmh`, `df_rp`, `df_condition`\n",
    "   - Merge **patient data** with medical conditions.\n",
    "   - Encode **family member relationships** as features.\n",
    "   - Define **multi-label classification labels** from patient conditions.\n",
    "   - Prevent **data leakage** by removing disease names from condition descriptions.\n",
    "\n",
    "### [**3. Constructing Graph Data (Graph Preparation)**](#3-constructing-graph-data-graph-preparation)\n",
    "   **Keywords**: `patient_id_map`, `edge_index`, `torch.tensor`, `Data(x=node_features, edge_index=edge_index)`\n",
    "   - Represent **patients as nodes** in the GNN.\n",
    "   - Use **TF-IDF** to generate **node features** from medical condition descriptions.\n",
    "   - Construct **edges** based on patient relationships from **RelatedPerson** data.\n",
    "\n",
    "### [**4. Train-Test Splitting for Model Training (Iterative Train-Test Split)**](#4-train-test-splitting-for-model-training-iterative-train-test-split)\n",
    "   **Keywords**: `iterative_train_test_split`, `X_train`, `Y_train`, `X_val`, `Y_val`\n",
    "   - Use **iterative train-test split** to ensure balanced label distribution.\n",
    "   - Split the data into **training (80%)** and **validation (20%)** sets.\n",
    "   - Convert features and labels into **PyTorch tensors** for compatibility with GNN models.\n",
    "\n",
    "### [**5. Graph Construction for Training and Validation**](#5-graph-construction-for-training-and-validation)\n",
    "   **Keywords**: `train_graph`, `val_graph`, `graph.clone()`\n",
    "   - Create **two separate graphs**:\n",
    "     - **Training Graph (`train_graph`)** for model training.\n",
    "     - **Validation Graph (`val_graph`)** for model evaluation.\n",
    "   - Maintain the **same edge connections** but update **node features** according to the data split.\n",
    "\n",
    "### [**6. GNN Model Definition**](#6-gnn-model-definition)\n",
    "   **Keywords**: `class GNNModel`, `GCNConv`, `F.relu`\n",
    "   - Define a **Graph Neural Network (GNN)** model using `torch_geometric.nn.GCNConv`.\n",
    "   - Implement **two graph convolution layers**:\n",
    "     - First layer transforms input features (`in_channels → hidden_channels`).\n",
    "     - Second layer maps hidden representations to the target labels (`hidden_channels → out_channels`).\n",
    "   - Apply **ReLU activation** for non-linearity.\n",
    "\n",
    "### [**7. Model Training with Validation**](#7-model-training-with-validation)\n",
    "   **Keywords**: `loss_fn`, `optimizer`, `loss_train`, `loss_val`\n",
    "   - Train the model using:\n",
    "     - **Adam optimizer** for weight updates.\n",
    "     - **Binary Cross-Entropy Loss (`BCEWithLogitsLoss`)** for multi-label classification.\n",
    "   - Perform **forward and backward propagation** on `train_graph`.\n",
    "   - Evaluate model performance on `val_graph` after each epoch.\n",
    "   - Print **training loss and validation loss** every 10 epochs.\n",
    "\n",
    "### [**8. Model and Vectorizer Saving**](#8-model-and-vectorizer-saving)\n",
    "   **Keywords**: `torch.save`, `pickle.dump`\n",
    "   - Save the trained **GNN model weights** (`gnn_model_weights.pt`).\n",
    "   - Save the **TF-IDF vectorizer** (`tfidf.pkl`) for use in inference.\n",
    "\n",
    "---\n",
    "\n",
    "## **Installation Requirements**\n",
    "To run this notebook, install the required dependencies using:\n",
    "\n",
    "```bash\n",
    "pip install torch torch-geometric scikit-learn fastapi hypercorn numpy pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extracting FHIR JSON Data (FHIR Extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# ========================\n",
    "# Helper Functions\n",
    "# ========================\n",
    "\n",
    "def extract_id(ref):\n",
    "    \"\"\"Extracts the ID from a reference string.\"\"\"\n",
    "    if ref.startswith(\"Patient/\"):\n",
    "        return ref.split(\"/\")[-1]\n",
    "    elif ref.startswith(\"RelatedPerson/\"):\n",
    "        return ref.split(\"/\")[-1]\n",
    "    elif ref.startswith(\"urn:uuid:\"):\n",
    "        return ref.split(\":\")[-1]\n",
    "    else:\n",
    "        return ref\n",
    "\n",
    "def load_json(filepath):\n",
    "    \"\"\"Loads a JSON file and returns its content.\"\"\"\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_as_csv(data, output_filepath):\n",
    "    \"\"\"Saves data as a CSV file.\"\"\"\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_filepath, index=False)\n",
    "    print(f\"CSV saved at {output_filepath}\")\n",
    "\n",
    "def save_as_json(data, output_filepath):\n",
    "    \"\"\"Saves data as a JSON file.\"\"\"\n",
    "    with open(output_filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(f\"JSON saved at {output_filepath}\")\n",
    "\n",
    "# ========================\n",
    "# Extraction Functions for Each Resource\n",
    "# ========================\n",
    "\n",
    "def extract_patients(data):\n",
    "    \"\"\"Extracts patient information including ID, birth date, gender, and name.\"\"\"\n",
    "    extracted = []\n",
    "    for p in data:\n",
    "        extracted.append({\n",
    "            \"patient_id\": p.get(\"id\", \"\"),\n",
    "            \"birthDate\": p.get(\"birthDate\", \"\"),\n",
    "            \"gender\": p.get(\"gender\", \"\"),\n",
    "            \"name\": p.get(\"name\", [{\"family\": \"Unknown\"}])[0].get(\"family\", \"Unknown\")\n",
    "        })\n",
    "    return extracted\n",
    "\n",
    "def extract_family_member_history(data):\n",
    "    \"\"\"Extracts family medical history, including patient ID, relationship type, and conditions.\"\"\"\n",
    "    extracted = []\n",
    "    for rec in data:\n",
    "        patient_ref = rec.get(\"patient\", {}).get(\"reference\", \"\")\n",
    "        patient_id = extract_id(patient_ref)\n",
    "\n",
    "        # Extract relationship type if available\n",
    "        relationship = \"\"\n",
    "        if \"relationship\" in rec and \"coding\" in rec[\"relationship\"] and rec[\"relationship\"][\"coding\"]:\n",
    "            relationship = rec[\"relationship\"][\"coding\"][0].get(\"display\", \"\")\n",
    "\n",
    "        # Extract medical conditions if available\n",
    "        conditions = []\n",
    "        if \"condition\" in rec:\n",
    "            for cond in rec[\"condition\"]:\n",
    "                cond_text = cond.get(\"code\", {}).get(\"text\", \"\")\n",
    "                if cond_text:\n",
    "                    conditions.append(cond_text)\n",
    "\n",
    "        extracted.append({\n",
    "            \"family_member_history_id\": rec.get(\"id\", \"\"),\n",
    "            \"patient_id\": patient_id,\n",
    "            \"relationship\": relationship,\n",
    "            \"conditions\": \"; \".join(conditions)  # Concatenates conditions if multiple exist\n",
    "        })\n",
    "    return extracted\n",
    "\n",
    "def extract_related_person(data):\n",
    "    \"\"\"Extracts related person details including ID, relationship, name, gender, and birth date.\"\"\"\n",
    "    extracted = []\n",
    "    for rec in data:\n",
    "        patient_ref = rec.get(\"patient\", {}).get(\"reference\", \"\")\n",
    "        patient_id = extract_id(patient_ref)\n",
    "\n",
    "        # Extract and concatenate relationship descriptions if multiple exist\n",
    "        relationship = \", \".join([r.get(\"text\", \"\") for r in rec.get(\"relationship\", [])])\n",
    "\n",
    "        # Extract related person's name if available\n",
    "        rp_name = \"\"\n",
    "        if \"name\" in rec and isinstance(rec[\"name\"], list) and len(rec[\"name\"]) > 0:\n",
    "            rp_name = rec[\"name\"][0].get(\"family\", \"\")\n",
    "\n",
    "        extracted.append({\n",
    "            \"related_person_id\": extract_id(rec.get(\"id\", \"\")),\n",
    "            \"patient_id\": patient_id,\n",
    "            \"relationship\": relationship,\n",
    "            \"rp_name\": rp_name,\n",
    "            \"gender\": rec.get(\"gender\", \"\"),\n",
    "            \"birthDate\": rec.get(\"birthDate\", \"\")\n",
    "        })\n",
    "    return extracted\n",
    "\n",
    "def extract_conditions(data):\n",
    "    \"\"\"Extracts medical conditions associated with patients.\"\"\"\n",
    "    extracted = []\n",
    "    for rec in data:\n",
    "        subject_ref = rec.get(\"subject\", {}).get(\"reference\", \"\")\n",
    "        patient_id = extract_id(subject_ref)\n",
    "        disease = rec.get(\"code\", {}).get(\"text\", \"\")\n",
    "\n",
    "        extracted.append({\n",
    "            \"condition_id\": rec.get(\"id\", \"\"),\n",
    "            \"patient_id\": patient_id,\n",
    "            \"disease\": disease\n",
    "        })\n",
    "    return extracted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Patient from synthea/output/processed/Patient.json\n",
      "DataFrame for Patient created with shape: (1252, 4)\n",
      "Processing FamilyMemberHistory from synthea/output/processed/FamilyMemberHistory.json\n",
      "DataFrame for FamilyMemberHistory created with shape: (1930, 4)\n",
      "Processing RelatedPerson from synthea/output/processed/RelatedPerson.json\n",
      "DataFrame for RelatedPerson created with shape: (2949, 6)\n",
      "Processing Condition from synthea/output/processed/Condition.json\n",
      "DataFrame for Condition created with shape: (52248, 3)\n",
      "\n",
      "Sample DataFrame for Patient:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>birthDate</th>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12f6dd3f-9c76-02ac-540f-8a17f3a6fbf5</td>\n",
       "      <td>1970-03-21</td>\n",
       "      <td>female</td>\n",
       "      <td>Abshire638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9c87fb9d-f2a6-3149-128a-2a80bd17089c</td>\n",
       "      <td>2014-04-29</td>\n",
       "      <td>female</td>\n",
       "      <td>Maggio310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d7e1e837-68df-de63-a981-10012d427bce</td>\n",
       "      <td>1993-01-19</td>\n",
       "      <td>male</td>\n",
       "      <td>Rosenbaum794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c1a091f1-de53-7b04-20d4-a5dff9ecbfdb</td>\n",
       "      <td>1931-06-04</td>\n",
       "      <td>male</td>\n",
       "      <td>Donnelly343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4de6e038-9511-5a10-fd6a-3fdc7be5512a</td>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>female</td>\n",
       "      <td>Kuhn96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             patient_id   birthDate  gender          name\n",
       "0  12f6dd3f-9c76-02ac-540f-8a17f3a6fbf5  1970-03-21  female    Abshire638\n",
       "1  9c87fb9d-f2a6-3149-128a-2a80bd17089c  2014-04-29  female     Maggio310\n",
       "2  d7e1e837-68df-de63-a981-10012d427bce  1993-01-19    male  Rosenbaum794\n",
       "3  c1a091f1-de53-7b04-20d4-a5dff9ecbfdb  1931-06-04    male   Donnelly343\n",
       "4  4de6e038-9511-5a10-fd6a-3fdc7be5512a  2022-06-27  female        Kuhn96"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample DataFrame for FamilyMemberHistory:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family_member_history_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>relationship</th>\n",
       "      <th>conditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family-bc5c2fb6-e807-c398-4305-55c2ed43a8be-</td>\n",
       "      <td>12f6dd3f-9c76-02ac-540f-8a17f3a6fbf5</td>\n",
       "      <td>Sister</td>\n",
       "      <td>Hypertension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>family-2fff7b31-f1b2-e272-a6fc-85b5093966c8-</td>\n",
       "      <td>9c87fb9d-f2a6-3149-128a-2a80bd17089c</td>\n",
       "      <td>Father</td>\n",
       "      <td>Hypertension; Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>family-3788a732-4aad-de84-314b-314df978289b-</td>\n",
       "      <td>9c87fb9d-f2a6-3149-128a-2a80bd17089c</td>\n",
       "      <td>Mother</td>\n",
       "      <td>Diabetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>family-168f2fe5-29b4-ad16-85b3-5046ac1f22d5-</td>\n",
       "      <td>9c87fb9d-f2a6-3149-128a-2a80bd17089c</td>\n",
       "      <td>Brother</td>\n",
       "      <td>Hypertension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>family-31643781-87b3-b1e3-f480-7c5425baf882-</td>\n",
       "      <td>d7e1e837-68df-de63-a981-10012d427bce</td>\n",
       "      <td>Father</td>\n",
       "      <td>Diabetes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       family_member_history_id  \\\n",
       "0  family-bc5c2fb6-e807-c398-4305-55c2ed43a8be-   \n",
       "1  family-2fff7b31-f1b2-e272-a6fc-85b5093966c8-   \n",
       "2  family-3788a732-4aad-de84-314b-314df978289b-   \n",
       "3  family-168f2fe5-29b4-ad16-85b3-5046ac1f22d5-   \n",
       "4  family-31643781-87b3-b1e3-f480-7c5425baf882-   \n",
       "\n",
       "                             patient_id relationship            conditions  \n",
       "0  12f6dd3f-9c76-02ac-540f-8a17f3a6fbf5       Sister          Hypertension  \n",
       "1  9c87fb9d-f2a6-3149-128a-2a80bd17089c       Father  Hypertension; Cancer  \n",
       "2  9c87fb9d-f2a6-3149-128a-2a80bd17089c       Mother              Diabetes  \n",
       "3  9c87fb9d-f2a6-3149-128a-2a80bd17089c      Brother          Hypertension  \n",
       "4  d7e1e837-68df-de63-a981-10012d427bce       Father              Diabetes  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample DataFrame for RelatedPerson:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related_person_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>relationship</th>\n",
       "      <th>rp_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bc5c2fb6-e807-c398-4305-55c2ed43a8be</td>\n",
       "      <td>12f6dd3f-9c76-02ac-540f-8a17f3a6fbf5</td>\n",
       "      <td>Sister</td>\n",
       "      <td>Legros616</td>\n",
       "      <td>female</td>\n",
       "      <td>1995-04-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2fff7b31-f1b2-e272-a6fc-85b5093966c8</td>\n",
       "      <td>9c87fb9d-f2a6-3149-128a-2a80bd17089c</td>\n",
       "      <td>Father</td>\n",
       "      <td>Kerluke267</td>\n",
       "      <td>female</td>\n",
       "      <td>1968-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3788a732-4aad-de84-314b-314df978289b</td>\n",
       "      <td>9c87fb9d-f2a6-3149-128a-2a80bd17089c</td>\n",
       "      <td>Mother</td>\n",
       "      <td>Harber290</td>\n",
       "      <td>female</td>\n",
       "      <td>1934-09-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>758a4a6f-2667-8a9f-3f8b-0d11d84690c4</td>\n",
       "      <td>9c87fb9d-f2a6-3149-128a-2a80bd17089c</td>\n",
       "      <td>Sister</td>\n",
       "      <td>Crooks415</td>\n",
       "      <td>male</td>\n",
       "      <td>1974-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>168f2fe5-29b4-ad16-85b3-5046ac1f22d5</td>\n",
       "      <td>9c87fb9d-f2a6-3149-128a-2a80bd17089c</td>\n",
       "      <td>Brother</td>\n",
       "      <td>Abernathy524</td>\n",
       "      <td>male</td>\n",
       "      <td>1918-08-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      related_person_id                            patient_id  \\\n",
       "0  bc5c2fb6-e807-c398-4305-55c2ed43a8be  12f6dd3f-9c76-02ac-540f-8a17f3a6fbf5   \n",
       "1  2fff7b31-f1b2-e272-a6fc-85b5093966c8  9c87fb9d-f2a6-3149-128a-2a80bd17089c   \n",
       "2  3788a732-4aad-de84-314b-314df978289b  9c87fb9d-f2a6-3149-128a-2a80bd17089c   \n",
       "3  758a4a6f-2667-8a9f-3f8b-0d11d84690c4  9c87fb9d-f2a6-3149-128a-2a80bd17089c   \n",
       "4  168f2fe5-29b4-ad16-85b3-5046ac1f22d5  9c87fb9d-f2a6-3149-128a-2a80bd17089c   \n",
       "\n",
       "  relationship       rp_name  gender   birthDate  \n",
       "0       Sister     Legros616  female  1995-04-29  \n",
       "1       Father    Kerluke267  female  1968-07-19  \n",
       "2       Mother     Harber290  female  1934-09-27  \n",
       "3       Sister     Crooks415    male  1974-10-17  \n",
       "4      Brother  Abernathy524    male  1918-08-10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample DataFrame for Condition:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>012b86ed-db33-e7d4-c219-bbae1288ffb6</td>\n",
       "      <td>12f6dd3f-9c76-02ac-540f-8a17f3a6fbf5</td>\n",
       "      <td>Received higher education (finding)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35c7b546-cd71-18e9-978a-96661be955b4</td>\n",
       "      <td>12f6dd3f-9c76-02ac-540f-8a17f3a6fbf5</td>\n",
       "      <td>Essential hypertension (disorder)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8bfe22c6-c111-6d77-78dd-f9a13f14d7fe</td>\n",
       "      <td>12f6dd3f-9c76-02ac-540f-8a17f3a6fbf5</td>\n",
       "      <td>Body mass index 30+ - obesity (finding)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40b4d77d-691e-6673-bd52-ef274b6d01ec</td>\n",
       "      <td>12f6dd3f-9c76-02ac-540f-8a17f3a6fbf5</td>\n",
       "      <td>History of tubal ligation (situation)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b5b9ba5d-6761-d10d-6a31-81d524c30821</td>\n",
       "      <td>12f6dd3f-9c76-02ac-540f-8a17f3a6fbf5</td>\n",
       "      <td>Chronic kidney disease stage 1 (disorder)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           condition_id                            patient_id  \\\n",
       "0  012b86ed-db33-e7d4-c219-bbae1288ffb6  12f6dd3f-9c76-02ac-540f-8a17f3a6fbf5   \n",
       "1  35c7b546-cd71-18e9-978a-96661be955b4  12f6dd3f-9c76-02ac-540f-8a17f3a6fbf5   \n",
       "2  8bfe22c6-c111-6d77-78dd-f9a13f14d7fe  12f6dd3f-9c76-02ac-540f-8a17f3a6fbf5   \n",
       "3  40b4d77d-691e-6673-bd52-ef274b6d01ec  12f6dd3f-9c76-02ac-540f-8a17f3a6fbf5   \n",
       "4  b5b9ba5d-6761-d10d-6a31-81d524c30821  12f6dd3f-9c76-02ac-540f-8a17f3a6fbf5   \n",
       "\n",
       "                                     disease  \n",
       "0        Received higher education (finding)  \n",
       "1          Essential hypertension (disorder)  \n",
       "2    Body mass index 30+ - obesity (finding)  \n",
       "3      History of tubal ligation (situation)  \n",
       "4  Chronic kidney disease stage 1 (disorder)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Folder containing processed FHIR data\n",
    "processed_folder = \"synthea/output/processed/\"\n",
    "\n",
    "# Resources considered useful for predictive modeling\n",
    "resources = [\"Patient\", \"FamilyMemberHistory\", \"RelatedPerson\", \"Condition\"]\n",
    "\n",
    "# Mapping of resources to corresponding extraction functions\n",
    "extraction_functions = {\n",
    "    \"Patient\": extract_patients,\n",
    "    \"FamilyMemberHistory\": extract_family_member_history,\n",
    "    \"RelatedPerson\": extract_related_person,\n",
    "    \"Condition\": extract_conditions\n",
    "}\n",
    "\n",
    "# Dictionary to store extracted DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "for res in resources:\n",
    "    filepath = os.path.join(processed_folder, f\"{res}.json\")\n",
    "    \n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"Processing {res} from {filepath}\")\n",
    "        data = load_json(filepath)\n",
    "\n",
    "        # Convert dictionary to list if necessary\n",
    "        if isinstance(data, dict):\n",
    "            data = [data]\n",
    "\n",
    "        extracted_data = extraction_functions[res](data)\n",
    "        df = pd.DataFrame(extracted_data)\n",
    "        dataframes[res] = df\n",
    "        print(f\"DataFrame for {res} created with shape: {df.shape}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"File {res}.json not found in {processed_folder}\")\n",
    "\n",
    "# Display sample rows from each DataFrame\n",
    "for res, df in dataframes.items():\n",
    "    print(f\"\\nSample DataFrame for {res}:\")\n",
    "    display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing and Training DataFrame Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# === 1. Load Data ===\n",
    "df_patient = dataframes[\"Patient\"]\n",
    "df_fmh = dataframes[\"FamilyMemberHistory\"]\n",
    "df_rp = dataframes[\"RelatedPerson\"]\n",
    "df_condition = dataframes[\"Condition\"]\n",
    "\n",
    "# === 2. Group Condition by patient_id and concatenate disease names ===\n",
    "df_condition_grouped = (\n",
    "    df_condition.groupby(\"patient_id\")[\"disease\"]\n",
    "    .apply(lambda x: \" \".join(x))\n",
    "    .reset_index()\n",
    "    .rename(columns={\"disease\": \"patient_conditions_text\"})\n",
    ")\n",
    "\n",
    "# Merge df_patient with patient conditions\n",
    "df_training = pd.merge(df_patient, df_condition_grouped, on=\"patient_id\", how=\"left\").fillna(\"\")\n",
    "\n",
    "# === 3. Process FamilyMemberHistory & RelatedPerson as additional features ===\n",
    "\n",
    "# Process FamilyMemberHistory\n",
    "df_fmh_grouped = (\n",
    "    df_fmh.groupby([\"patient_id\", \"relationship\"])[\"conditions\"]\n",
    "    .apply(lambda x: \"; \".join(x.dropna().unique()))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_fmh_pivot = df_fmh_grouped.pivot(index=\"patient_id\", columns=\"relationship\", values=\"conditions\").reset_index()\n",
    "df_fmh_pivot = df_fmh_pivot.rename(columns=lambda x: x.lower() + \"_condition\" if x != \"patient_id\" else x)\n",
    "df_training = pd.merge(df_training, df_fmh_pivot, on=\"patient_id\", how=\"left\").fillna(\"\")\n",
    "\n",
    "# Process RelatedPerson\n",
    "df_rp_condition = pd.merge(df_rp, df_condition_grouped, left_on=\"related_person_id\", right_on=\"patient_id\", how=\"left\")\n",
    "df_rp_condition.drop(columns=[\"patient_id_y\"], inplace=True)\n",
    "\n",
    "df_rp_grouped = (\n",
    "    df_rp_condition.groupby([\"patient_id_x\", \"relationship\"])[\"patient_conditions_text\"]\n",
    "    .apply(lambda x: \"; \".join(x.dropna().unique()))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_rp_pivot = df_rp_grouped.pivot(index=\"patient_id_x\", columns=\"relationship\", values=\"patient_conditions_text\").reset_index()\n",
    "df_rp_pivot = df_rp_pivot.rename(columns=lambda x: x.lower() + \"_related_condition\" if x != \"patient_id_x\" else x)\n",
    "df_training = pd.merge(df_training, df_rp_pivot, left_on=\"patient_id\", right_on=\"patient_id_x\", how=\"left\").fillna(\"\")\n",
    "\n",
    "# === 4. Create Multi-Label Targets for Each Patient ===\n",
    "target_diseases = [\"Diabetes\", \"Hypertension\", \"Cancer\", \"Heart Disease\", \"Alzheimer\", \"Asthma\"]\n",
    "\n",
    "for disease in target_diseases:\n",
    "    df_training[disease] = df_training[\"patient_conditions_text\"].apply(lambda x: 1 if disease.lower() in str(x).lower() else 0)\n",
    "\n",
    "# === 5. Remove Disease Names from Text Features to Prevent Data Leakage ===\n",
    "def remove_target_diseases_partial(text, target_diseases, remove_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Removes disease names from text for a subset of patients (default 50%) \n",
    "    to simulate real-world scenarios where information may be incomplete.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "\n",
    "    # Randomly determine if diseases should be removed\n",
    "    if random.random() > remove_ratio:  # Keep diseases for 50% of cases\n",
    "        return text\n",
    "\n",
    "    text = text.lower()\n",
    "    for disease in target_diseases:\n",
    "        pattern = r\"\\b\\w*\" + re.escape(disease.lower()) + r\"\\w*\\b\"\n",
    "        text = re.sub(pattern, \"\", text).strip()\n",
    "\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "# Apply the disease removal function to patient conditions\n",
    "df_training[\"patient_conditions_text_cleaned\"] = df_training[\"patient_conditions_text\"].apply(\n",
    "    lambda x: remove_target_diseases_partial(x, target_diseases, remove_ratio=0.5)\n",
    ")\n",
    "\n",
    "# === 6. Create Node Representations with TF-IDF ===\n",
    "text_columns = [\n",
    "    \"patient_conditions_text_cleaned\",\n",
    "]\n",
    "\n",
    "# Concatenate all text features\n",
    "df_training[\"all_text\"] = df_training[text_columns].apply(lambda x: \" \".join(x.dropna()), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Constructing Graph Data (Graph Preparation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph successfully created.\n",
      "Data(x=[1252, 425], edge_index=[2, 2949])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Apply TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(max_features=1000)\n",
    "X_tfidf = tfidf.fit_transform(df_training[\"all_text\"])\n",
    "\n",
    "# Map patient_id to a unique index\n",
    "patient_ids = df_training[\"patient_id\"].tolist()\n",
    "patient_id_map = {pid: i for i, pid in enumerate(patient_ids)}\n",
    "\n",
    "# === 7. Construct Graph Edges from RelatedPerson Relationships ===\n",
    "edge_index = []\n",
    "for _, row in df_rp.iterrows():\n",
    "    if row[\"patient_id\"] in patient_id_map and row[\"related_person_id\"] in patient_id_map:\n",
    "        edge_index.append([patient_id_map[row[\"patient_id\"]], patient_id_map[row[\"related_person_id\"]]])\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).T  # Convert to PyTorch Geometric format\n",
    "\n",
    "# === 8. Create PyTorch Geometric Graph ===\n",
    "node_features = torch.tensor(X_tfidf.toarray(), dtype=torch.float32)\n",
    "graph = Data(x=node_features, edge_index=edge_index)\n",
    "\n",
    "# === 9. Convert Labels to Tensor ===\n",
    "labels_tensor = torch.tensor(df_training[target_diseases].values, dtype=torch.float32)\n",
    "\n",
    "print(\"Graph successfully created.\")\n",
    "print(graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train-Test Splitting for Model Training (Iterative Train-Test Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "# === Iterative Train-Test Split (Train-Validation) ===\n",
    "X = node_features.numpy()  # Konversi node features ke NumPy Array\n",
    "Y = labels_tensor.numpy()  # Konversi label ke NumPy Array\n",
    "\n",
    "# 80% Train, 20% Validation menggunakan Iterative Stratification\n",
    "X_train, Y_train, X_val, Y_val = iterative_train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "# Konversi kembali ke Tensor\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "Y_val_tensor = torch.tensor(Y_val, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Buat Graph untuk Train & Validation ===\n",
    "train_graph = graph.clone()\n",
    "train_graph.x = X_train_tensor\n",
    "train_graph.edge_index = graph.edge_index\n",
    "\n",
    "val_graph = graph.clone()\n",
    "val_graph.x = X_val_tensor\n",
    "val_graph.edge_index = graph.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graph = Data(x=X_train_tensor, edge_index=edge_index_train)\n",
    "val_graph = Data(x=X_val_tensor, edge_index=edge_index_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. GNN Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import numpy as np\n",
    "\n",
    "# === Define the GNN Model ===\n",
    "class GNNModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Initializes a Graph Convolutional Network (GCN) model.\n",
    "\n",
    "        Args:\n",
    "            input_dim (int): Number of input features per node.\n",
    "            hidden_dim (int): Number of hidden layer neurons.\n",
    "            output_dim (int): Number of output classes (multi-label classification).\n",
    "        \"\"\"\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Forward pass through the GNN model.\n",
    "\n",
    "        Args:\n",
    "            data (torch_geometric.data.Data): Graph data containing node features and edge indices.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output logits for each node.\n",
    "        \"\"\"\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)  # Activation function\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Initialize the GNN Model ===\n",
    "hidden_dim = 64  # Number of hidden layer neurons\n",
    "output_dim = len(target_diseases)  # Number of output labels for multi-label classification\n",
    "\n",
    "# Initialize the model with input features, hidden layer, and output labels\n",
    "model = GNNModel(input_dim=node_features.shape[1], hidden_dim=hidden_dim, output_dim=output_dim)\n",
    "\n",
    "# Define the optimizer (Adam optimizer with a learning rate of 0.01)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Define the loss function (Binary Cross-Entropy with Logits for multi-label classification)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Model Training with Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 0.6939, Val Loss: 0.6565  Val   F1-Micro: 0.6397, Val   F1-Macro: 0.3147\n",
      "Epoch 10, Train Loss: 0.5609, Val Loss: 0.5546  Val   F1-Micro: 0.6661, Val   F1-Macro: 0.3520\n",
      "Epoch 20, Train Loss: 0.5402, Val Loss: 0.5408  Val   F1-Micro: 0.6863, Val   F1-Macro: 0.3735\n",
      "Epoch 30, Train Loss: 0.5284, Val Loss: 0.5325  Val   F1-Micro: 0.6843, Val   F1-Macro: 0.3753\n",
      "Epoch 40, Train Loss: 0.5172, Val Loss: 0.5337  Val   F1-Micro: 0.6678, Val   F1-Macro: 0.3722\n",
      "Epoch 50, Train Loss: 0.5060, Val Loss: 0.5416  Val   F1-Micro: 0.6559, Val   F1-Macro: 0.3718\n",
      "Epoch 60, Train Loss: 0.4955, Val Loss: 0.5521  Val   F1-Micro: 0.6498, Val   F1-Macro: 0.3807\n",
      "Epoch 70, Train Loss: 0.4859, Val Loss: 0.5614  Val   F1-Micro: 0.6533, Val   F1-Macro: 0.3953\n",
      "Epoch 80, Train Loss: 0.4771, Val Loss: 0.5711  Val   F1-Micro: 0.6539, Val   F1-Macro: 0.4077\n",
      "Epoch 90, Train Loss: 0.4689, Val Loss: 0.5814  Val   F1-Micro: 0.6534, Val   F1-Macro: 0.4162\n",
      "GNN model training completed with validation set and F1-score evaluation!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# === Train the GNN Model with Validation and F1-score Evaluation ===\n",
    "num_epochs = 100  # Number of training epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass on training data\n",
    "    logits_train = model(train_graph)  \n",
    "    loss_train = loss_fn(logits_train, Y_train_tensor)  # Compute training loss\n",
    "    \n",
    "    # Backpropagation and optimization step\n",
    "    optimizer.zero_grad()\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Validation step\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient computation for validation\n",
    "        logits_val = model(val_graph)\n",
    "        loss_val = loss_fn(logits_val, Y_val_tensor)  # Compute validation loss\n",
    "\n",
    "        # Convert logits to probabilities\n",
    "        train_probs = torch.sigmoid(logits_train).cpu().numpy()\n",
    "        val_probs = torch.sigmoid(logits_val).cpu().numpy()\n",
    "\n",
    "        # Convert probabilities to binary predictions using 0.5 threshold\n",
    "        train_preds = (train_probs >= 0.5).astype(int)\n",
    "        val_preds = (val_probs >= 0.5).astype(int)\n",
    "\n",
    "        # Compute F1-scores for training and validation\n",
    "        f1_micro_train = f1_score(Y_train_tensor.cpu().numpy(), train_preds, average='micro')\n",
    "        f1_macro_train = f1_score(Y_train_tensor.cpu().numpy(), train_preds, average='macro')\n",
    "\n",
    "        f1_micro_val = f1_score(Y_val_tensor.cpu().numpy(), val_preds, average='micro')\n",
    "        f1_macro_val = f1_score(Y_val_tensor.cpu().numpy(), val_preds, average='macro')\n",
    "\n",
    "    # Print training and validation loss every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Train Loss: {loss_train.item():.4f}, Val Loss: {loss_val.item():.4f}  Val   F1-Micro: {f1_micro_val:.4f}, Val   F1-Macro: {f1_macro_val:.4f}\")\n",
    " \n",
    "print(\"GNN model training completed with validation set and F1-score evaluation!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Model and Vectorizer Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN model weights saved to 'gnn_model_weights.pt'.\n",
      "TF-IDF vectorizer saved to 'tfidf.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Save the trained GNN model weights\n",
    "torch.save(model.state_dict(), \"gnn_model_weights.pt\")\n",
    "print(\"GNN model weights saved to 'gnn_model_weights.pt'.\")\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "with open(\"tfidf.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tfidf, f)\n",
    "\n",
    "print(\"TF-IDF vectorizer saved to 'tfidf.pkl'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
